{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85c3a198",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f294bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, Activation, Dense, Input, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Flatten, MaxPooling2D, GlobalAveragePooling2D, LeakyReLU\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# increase width of jupyter notebook\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6192accc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df  = pd.read_csv('test.csv')\n",
    "\n",
    "train_label = train_df['label']\n",
    "train_label = to_categorical(train_label) # Converts a class vector (integers) to binary class matrix\n",
    "train_data  = (train_df.iloc[:, 1:].values.astype('float32') / 255.0 ).reshape(-1, 28, 28, 1)\n",
    "test_data   = (test_df.iloc[:,:].values.astype('float32') / 255.0 ).reshape(-1, 28, 28, 1)\n",
    "# reshaping the data, images are 28 x 28 pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5a1b76",
   "metadata": {},
   "source": [
    "### visualize distribution of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc62c139",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = pd.value_counts(train_df['label'].values)\n",
    "count.plot.bar(figsize = (10,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce37790",
   "metadata": {},
   "source": [
    "### Build CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "817d20b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = RMSprop(learning_rate=0.05,\n",
    "                rho=0.9,\n",
    "                momentum=0.1,\n",
    "                epsilon=1e-07,\n",
    "                centered=True,\n",
    "                name='RMSprop')\n",
    "nets  = 15\n",
    "model = [0] * nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98c211ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization\n",
    "for i in range(nets):\n",
    "    model[i] = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(64, (3,3), padding='same', input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(64,  (3,3), padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(64,  (3,3), padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "        tf.keras.layers.Conv2D(128, (3,3), padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(128, (3,3), padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(128, (3,3), padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Dropout(0.25),    \n",
    "\n",
    "        tf.keras.layers.Conv2D(256, (3,3), padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(256, (3,3), padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(256),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model[i].compile(loss = 'categorical_crossentropy',\n",
    "                    optimizer = optim,\n",
    "                    metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320fa849",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=10,  \n",
    "        zoom_range = 0.15,  \n",
    "        width_shift_range=0.1, \n",
    "        height_shift_range=0.1)\n",
    "history = [0] * nets\n",
    "epochs = 10\n",
    "\n",
    "for i in range(nets):\n",
    "    X_train2, X_val2, Y_train2, Y_val2 = train_test_split(train_data, train_label, test_size = 0.1, stratify = train_label)\n",
    "    \n",
    "    history[i] = model[i].fit_generator(datagen.flow(X_train2,Y_train2, batch_size=64),\n",
    "        epochs = epochs, steps_per_epoch = X_train2.shape[0]//64,  \n",
    "        validation_data = (X_val2,Y_val2), verbose=0)\n",
    "    print('CNN {0:d}:  Epochs = {1:d}, Train acc = {2:.5f}, Validation acc = {3:.5f}'.format(\n",
    "        i+1,epochs,max(history[i].history['accuracy']),max(history[i].history['val_accuracy']) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a16731",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb750a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ca85f16",
   "metadata": {},
   "source": [
    "### Save predictions to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9de0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.zeros( (test_data.shape[0], 10) ) \n",
    "for j in range(nets):\n",
    "    results = results + model[j].predict(test_data)\n",
    "results = np.argmax(results,axis = 1)\n",
    "results = pd.Series(results,name = 'Label')\n",
    "submission = pd.concat([pd.Series(range(1, 28001),name = 'ImageId'), results],axis = 1)\n",
    "submission.to_csv('submission_cnn.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
